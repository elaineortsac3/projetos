##Transfer Learning - Elaine

###1. Importando bibliotecas

#Limpa widgets interativos antigos, se existirem
from IPython.display import display
import ipywidgets as widgets

widgets.Widget.close_all()

import tensorflow as tf
import tensorflow_datasets as tfds
from tensorflow.keras.applications import VGG16
from tensorflow.keras import layers, models
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
from matplotlib.pyplot import imshow
import numpy as np


###2. Carregar Dataset (Cats vs Dogs)

#https://www.tensorflow.org/datasets/catalog/cats_vs_dogs

(train_data, test_data), ds_info = tfds.load(
    'cats_vs_dogs',
    split=['train[:80%]', 'train[80%:]'],
    with_info=True,
    as_supervised=True
)

###3. Pré-processar dados

- Ajuste do tamanho das imagens, normalização de pixels, agrupar em lotes

IMG_SIZE = 224 #VGG16 espera 224x224

def format_example(image, label):
  image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))
  image = image / 255.0 #normalização
  return image, label

BATCH_SIZE = 32

train_batches = (train_data
                   .map(format_example)
                   .shuffle(1000)
                   .batch(BATCH_SIZE)
                   .prefetch(1))
val_batches = (test_data
                 .map(format_example)
                 .batch(BATCH_SIZE)
                 .prefetch(1))

##4. Carregar o modelo VGG16 pré-treinado


base_model = VGG16(input_shape=(IMG_SIZE, IMG_SIZE, 3),
                   include_top=False, #removi a última camada (1000 classes)
                   weights='imagenet')

base_model.trainable = False #congelei o modelo

###5. Criar o modelo completo (com nova cabeça)

model = models.Sequential([
                           base_model,
                           layers.Flatten(),
                           layers.Dense(256, activation= 'relu'),
                           layers.Dropout(0.5),
                           layers.Dense(1, activation='sigmoid')
                           ])

###6. Compliar e treinar o modelo

model.compile(optimizer=Adam(learning_rate=1e-4),
              loss='binary_crossentropy',
              metrics=['accuracy'])

history = model.fit(train_batches,
                     epochs=5, #Para teste rodei com 2 porque estava travando depois de horas
                     validation_data=val_batches)

###7. Avaliar e visualizar os resultados

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(5)

plt.figure(figsize=(12,6))
plt.subplot(1,2,1)
plt.plot(epochs_range, acc, label='Acurária Treino')
plt.plot(epochs_range, val_acc, label='Acurária Validação')
plt.legend()
plt.title('Acurácia')

plt.subplot(122)
plt.plot(epochs_range, loss, label='Loss Treino')
plt.plot(epochs_range, val_loss, label='Loss Validação')
plt.legend()
plt.title('Perda (Loss)')
plt.show()
















